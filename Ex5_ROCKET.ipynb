{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex5 ROCKET-Elad_Eatah.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oolnfp8c1XYg"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OJLISU41OLY"
      },
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDvR43K01hB4"
      },
      "source": [
        "#ROCKET components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i3da_dK1kAE"
      },
      "source": [
        "## 1D Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V7vI16gDXHP"
      },
      "source": [
        "This method is obviously not as optimized as the paper's code (no Numba compilation is performed here). For further tuning, one may implement it in Cython (or even in C) or compile it using Numba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0mq4ehk1guR"
      },
      "source": [
        "def conv_1D_kernel(input_sequence: int, weights: List[float], stride: int, dilation: int, padding: int) -> List[float]:\n",
        "    sequences_count: int = input_sequence.shape[0]\n",
        "    input_seq_len: int = input_sequence.shape[1]\n",
        "    kernel_len: int = len(weights)\n",
        "    output_len: int = int((input_seq_len + 2 * padding - dilation * (kernel_len - 1) - 1) // stride) + 1\n",
        "    last_sequence_index: int = int((input_seq_len + padding - dilation * (kernel_len - 1) - 1) // stride) + 1\n",
        "    indices_shift: int = output_len - last_sequence_index\n",
        "    output_seq: List[float] = np.zeros((sequences_count, output_len), dtype=np.float64)\n",
        "\n",
        "    for i in range(-indices_shift, last_sequence_index):\n",
        "\n",
        "        index = i\n",
        "\n",
        "        for specific_weight in weights:\n",
        "\n",
        "            # If the end of the input sequence was reached, the computation is complete.\n",
        "            if index >= input_seq_len:\n",
        "                break\n",
        "\n",
        "            # If there is a padding, the computation should first skip the first zero terms.\n",
        "            elif index >= 0:\n",
        "                output_seq[:, i + indices_shift] += specific_weight * input_sequence[:, index]\n",
        "            index += dilation\n",
        "\n",
        "    return output_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joyuD2mK1owv"
      },
      "source": [
        "## ROCKET Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB6YEjqG1Vtt"
      },
      "source": [
        "class ROCKET():\n",
        "    def __init__(self, kernels_num: int, input_length: int):\n",
        "        self._kernels_num: int = kernels_num  # K - number of conv kernels\n",
        "        self._input_length: int = input_length\n",
        "\n",
        "        self._kernel_lengths: List[int] = list()\n",
        "        self._biases: List[float] = list()\n",
        "        self._dilations: List[int] = list()\n",
        "        self._use_paddings: List[bool] = list()\n",
        "        self._weights: List[float] = list()\n",
        "\n",
        "    def fit(self, seed: int = 1995) -> None:\n",
        "        \"\"\"\n",
        "        Generating the random parameters of all the convolution kernels\n",
        "        (not actual fitting to some given data...)\n",
        "        \"\"\"\n",
        "\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self._kernel_lengths = rng.choice([7, 9, 11], self._kernels_num)\n",
        "        self._biases = rng.uniform(-1, 1, self._kernels_num)\n",
        "        self._use_paddings = rng.integers(2, size=self._kernels_num) > 0\n",
        "        self._weights = rng.normal(size=int(np.sum(self._kernel_lengths)))\n",
        "        dilations_exponents = np.log2((self._input_length - 1) / (self._kernel_lengths - 1))\n",
        "        self._dilations = np.power(2, rng.uniform(0, dilations_exponents)).astype(np.int32)\n",
        "\n",
        "\n",
        "    def apply(self, input_data):\n",
        "        \"\"\"\n",
        "        Generates the features-map for each sample in the input data.\n",
        "\n",
        "        Args:\n",
        "            input_data - an array of float64 with dimensions [N, input_len]\n",
        "\n",
        "        Returns:\n",
        "            An array of float64 with dimensions [N, 2*K]\n",
        "        \"\"\"\n",
        "        first_weight_index: int = 0\n",
        "        last_weight_index: int = 0\n",
        "        stride: int = 1  # Const\n",
        "        features_map = np.empty((input_data.shape[0], 2*self._kernels_num))\n",
        "\n",
        "        for kernel_ind, (kernel_length, bias, use_padding, dilation) in enumerate(zip(\n",
        "            self._kernel_lengths, self._biases, self._use_paddings, self._dilations)):\n",
        "\n",
        "            padding_len = 0 \n",
        "            if use_padding:\n",
        "                padding_len = int((kernel_length - 1) * dilation / 2)\n",
        "            last_weight_index += kernel_length\n",
        "            kernel_weights = self._weights[first_weight_index:last_weight_index]\n",
        "            kernel_weights -= kernel_weights.mean()\n",
        "                \n",
        "            # Performing the convolution and extracting the max and PPV features.\n",
        "            conv_output = conv_1D_kernel(input_data, kernel_weights, stride, dilation, padding_len)\n",
        "            features_map[:, 2*kernel_ind] = conv_output.max(axis=1) + bias\n",
        "            features_map[:, 2*kernel_ind + 1] = \\\n",
        "                np.count_nonzero(conv_output + bias > 0) / len(conv_output)\n",
        "            \n",
        "            first_weight_index = last_weight_index\n",
        "\n",
        "        return features_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXgPIZ8h19Db"
      },
      "source": [
        "## Logistic Regression + ROCKET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6gxAyy12CjB"
      },
      "source": [
        "class RocketLogisticRegression():\n",
        "    def __init__(self, kernels_num: int, input_length: int, max_iter: int = 100,\n",
        "                 seed: int = 1995, regularization: str = 'none'):\n",
        "        self._rocket = ROCKET(kernels_num, input_length)\n",
        "        self._rocket.fit(seed)\n",
        "        self._model = LogisticRegression(penalty=regularization, \n",
        "                                         max_iter=max_iter)\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # Scaling the input sequences to have 0 mean and 1 std,\n",
        "        # and then performing the features-transform.\n",
        "        transformed_X = self._rocket.apply(scale(X, axis=1))\n",
        "        self._model.fit(transformed_X, y)\n",
        "        \n",
        "    def predict(self, X):      \n",
        "        # Scaling the input sequences to have 0 mean and 1 std,\n",
        "        # and then performing the features-transform.\n",
        "        transformed_X = self._rocket.apply(scale(X, axis=1))\n",
        "        return self._model.predict(transformed_X)\n",
        "    \n",
        "    def score(self, X, y):      \n",
        "        # Scaling the input sequences to have 0 mean and 1 std,\n",
        "        # and then performing the features-transform.\n",
        "        transformed_X = self._rocket.apply(scale(X, axis=1))\n",
        "        return self._model.score(transformed_X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwh7ikPV2tn6"
      },
      "source": [
        "# Experiment on Real Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGxFVLf120pn"
      },
      "source": [
        "The used dataset is taken from [here](http://timeseriesclassification.com/description.php?Dataset=ECG5000). This is a dataset of ECG signals of length 140, which are classified into 5 different classes.\n",
        "The best accuracy (according to the link) on this dataset was achieved by COTE, which is **94.61%**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7vIVq7M3Ydr"
      },
      "source": [
        "Train set size: **500**, Test set size: **4500** (yes, it is **9** times bigger than the train set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb3idV1f3yqx",
        "outputId": "34cca825-b53e-4f0f-ff76-918e0d8d8fc5"
      },
      "source": [
        "classes_num: int = 5\n",
        "train_set = pd.read_csv('ECG5000_TRAIN.txt', header=None, sep='  ')\n",
        "train_y = train_set[0].to_numpy()\n",
        "train_X = train_set.drop(train_set.columns[[0]], axis=1).to_numpy()\n",
        "\n",
        "test_set = pd.read_csv('ECG5000_TEST.txt', header=None, sep='  ')\n",
        "test_y = test_set[0].to_numpy()\n",
        "test_X = test_set.drop(test_set.columns[[0]], axis=1).to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "BwBIicwI5Fq5",
        "outputId": "36231845-7313-4428-847b-02bde3168a32"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "axs[0].hist(train_y, bins=classes_num)\n",
        "axs[0].set_title('Train classifications histogram')\n",
        "axs[1].hist(test_y, bins=classes_num)\n",
        "axs[1].set_title('Test classifications histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjp-AZF6eQH"
      },
      "source": [
        "Both the train set and the test set consist of mostly sequences of classes **1** and **2**. \n",
        "This makes this dataset quiet skewed..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLvQ4Df54R-a",
        "outputId": "cc987f61-2565-47a0-beef-ef317f8f48e0"
      },
      "source": [
        "#@title **Applying ROCKET+LogisticRegression**\n",
        "kernels_num = 1000 #@param {type:\"integer\"}\n",
        "max_iterations = 100 #@param {type:\"integer\"}\n",
        "regularizer = \"none\" #@param [\"none\", \"l2\"]\n",
        "seed = 1995 #@param {type:\"integer\"}\n",
        "model = RocketLogisticRegression(kernels_num, train_X.shape[1], \n",
        "                                 max_iter=max_iterations, seed=seed,\n",
        "                                 regularization=regularizer)\n",
        "model.fit(train_X, train_y)\n",
        "train_pred = model.predict(train_X)\n",
        "print(f'Train accuracy: {model.score(train_X, train_pred)}')\n",
        "test_pred = model.predict(test_X)\n",
        "print(f'Test accuracy: {model.score(test_X, test_y)}')\n",
        "print(f'Confusion matrix:\\n {confusion_matrix(test_y, predictions)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 1.0\n",
            "Test accuracy: 0.9382222222222222\n",
            "Confusion matrix:\n",
            " [[2607    3    9    8    0]\n",
            " [   8 1512   25   43    2]\n",
            " [  15   24   37    7    3]\n",
            " [  14   92    5   64    0]\n",
            " [   7    8    3    2    2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x6VJ_3Bml4"
      },
      "source": [
        "The optimization reaches a 100% accuracy on the train set very quickly, while its test accuracy is **93.8** when using 1,000 convolution kernels.\n",
        "This is almost as good as the SOTA accuracy of COTE, but the total run-time is much shorter!\n",
        "(though most of these results are probably because of the skewness of the dataset...)"
      ]
    }
  ]
}